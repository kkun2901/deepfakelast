# 딥페이크 탐지 앱 - 프로젝트 문서

## 1. 프로젝트 개요 (6점, 각 1점)

### 1) 제품명
**딥페이크 탐지 앱 (Deepfake Detector App)**

### 2) 프로젝트 소개
Android 모바일 환경에서 실시간으로 딥페이크 영상을 탐지하고 분석하는 통합 애플리케이션입니다. React Native와 FastAPI 백엔드를 결합하여 구축되었으며, 플로팅 위젯 기반 스크린 레코딩과 딥러닝 모델(MesoNet)을 통한 정확한 딥페이크 탐지를 제공합니다.

사용자는 현재 사용 중인 앱 화면(예: 유튜브, 인스타그램, 틱톡 등)을 별도 앱 전환 없이 바로 녹화하고 분석할 수 있어, 의심스러운 영상을 발견 즉시 검증할 수 있습니다. 분석 결과는 타임라인 세그먼트 기반으로 제공됩니다.

### 3) 프로젝트 목표
- **즉시성**: 모바일 환경에서 실시간 딥페이크 탐지 서비스 제공
- **정확성**: MesoNet 딥러닝 모델을 통한 높은 탐지 정확도 달성
- **사용성**: 앱 전환 없이 플로팅 위젯으로 즉시 녹화 및 분석 가능
- **효율성**: 얼굴 감지 기반 스마트 프레임 추출 및 동적 프레임 샘플링으로 처리 속도 최적화

### 4) 해결하고자 하는 문제
1. **정보 검증의 어려움**: 소셜 미디어에서 빠르게 확산되는 딥페이크 영상을 신속하게 검증할 수 있는 도구 부족
2. **접근성 문제**: 기존 딥페이크 탐지 도구는 주로 PC 기반으로, 모바일 사용자가 즉시 사용하기 어려움
3. **검증 시간 지연**: 의심스러운 영상을 발견했을 때 별도 앱으로 전환하거나 파일을 다운로드하는 과정에서 시간 소모

### 5) 프로젝트가 필요한 이유
- **사회적 필요성**: 가짜 뉴스와 딥페이크 영상의 확산으로 인한 정보 신뢰도 저하 문제 해결
- **기술적 필요성**: 모바일 환경에서 실시간 딥페이크 탐지 기술의 필요성 증가
- **시장적 필요성**: B2C(일반 소비자), B2B(미디어 기업, 플랫폼 서비스), 연구 시장(대학 및 연구기관)에서의 수요

### 6) 목표 사용자
1. **일반 소비자 (18-45세)**: 소셜 미디어를 활발히 사용하며 정보 검증에 관심이 있는 사용자
2. **미디어 전문가 및 저널리스트**: 뉴스 확인 및 팩트체크를 수행하는 전문가
3. **연구자 및 개발자**: 딥페이크 탐지 모델 연구를 수행하는 연구자
4. **교육 관계자**: 미디어 리터러시 교육을 수행하는 교사 및 디지털 시민 교육 프로그램 운영자
5. **기업 및 조직**: 콘텐츠 검증이 필요한 플랫폼 서비스 기업 및 보안 및 인증 서비스를 제공하는 기업

---

## 2. 핵심 기능 (총 9점, 각 3점)

### 1) Must (없으면 성립 불가)

#### 백엔드 기능
- ✅ **딥페이크 탐지 API**: 비디오 파일을 받아 딥페이크 여부를 분석하고 결과 반환 (`POST /analyze-video/`)
- ✅ **딥러닝 모델 추론**: PyTorch 기반 MesoNet 모델을 활용한 딥페이크 탐지 추론
- ✅ **비디오 처리**: OpenCV를 활용한 영상 프레임 추출 및 전처리
- ✅ **얼굴 감지**: MediaPipe를 활용한 얼굴 감지 및 프레임 필터링
- ✅ **타임라인 생성**: 프레임별 분석 결과를 시간 구간별 세그먼트로 그룹화
- ✅ **결과 API**: 분석 결과를 JSON 형식으로 반환 (`GET /get-result/{video_id}`)

#### 프론트엔드 기능
- ✅ **비디오 녹화**: 카메라를 통한 직접 녹화 또는 앨범에서 영상 선택
- ✅ **비디오 업로드**: 선택한 영상을 백엔드 서버로 업로드
- ✅ **분석 결과 표시**: 타임라인 기반 분석 결과 시각화 및 확률 표시
- ✅ **Android 플로팅 위젯**: 다른 앱 위에 오버레이되어 스크린 레코딩 및 즉시 분석 가능

### 2) Should (있으면 UX 향상)

- ✅ **스마트 프레임 샘플링**: 영상 길이에 따라 동적으로 프레임 샘플 수 조정 (짧은 영상은 더 많은 프레임 추출)
- ✅ **로딩 애니메이션**: SVG 기반 로딩 애니메이션으로 사용자 대기 경험 개선
- ✅ **Firebase Storage 연동**: 영상 파일을 Firebase Storage에 안전하게 저장
- ✅ **타임라인 시각화**: 프레임별 분석 결과를 시간 구간별로 색상 코딩하여 표시

### 3) Could (있으면 재미/부가가치)

- ✅ **플로팅 위젯 커스터마이징**: 위젯 버튼 아이콘 및 배경 색상 커스터마이징
- ✅ **분석 결과 아이콘 변경**: 분석 완료 시 위젯 아이콘이 자동으로 변경되어 시각적 피드백 제공
- ✅ **커뮤니티 기능**: 딥페이크 탐지 결과를 공유하고 토론할 수 있는 커뮤니티 화면
- ✅ **리포트 생성**: 분석 결과를 기반으로 리포트 생성 및 다운로드
- ✅ **메트릭스 화면**: 분석 통계 및 성능 지표 확인

---

## 3. 사용자 시나리오 (5점)

### 시나리오 1: 플로팅 위젯을 통한 즉시 분석

```
1. 사용자가 유튜브 앱에서 의심스러운 영상을 발견
   ↓
2. 플로팅 위젯 버튼 클릭하여 위젯 활성화
   ↓
3. 녹화 버튼을 눌러 현재 화면 녹화 시작
   ↓
4. 영상 녹화 완료 후 분석 버튼 클릭
   ↓
5. 백엔드 서버로 영상 업로드 및 분석 요청
   ↓
6. 로딩 애니메이션 표시 (4개의 SVG 아이콘 순차 재생)
   ↓
7. 분석 완료 후 결과 팝업 카드 표시
   - 딥페이크 확률 (예: 86%)
   - FAKE/REAL 판정
   - 닫기 버튼
   ↓
8. 위젯 아이콘이 분석 결과 아이콘으로 자동 변경
```

### 시나리오 2: 앱 내에서 직접 영상 분석

```
1. 딥페이크 탐지 앱 실행
   ↓
2. 홈 화면에서 "영상으로 탐지" 버튼 클릭
   ↓
3. 갤러리에서 영상 선택
   ↓
4. "영상을 분석하시겠습니까?" 확인 팝업 표시
   ↓
5. "분석하기" 버튼 클릭
   ↓
6. 로딩 애니메이션 표시
   ↓
7. 분석 완료 후 결과 팝업 카드 표시
   - 딥페이크 확률
   - FAKE/REAL 판정
   - 닫기 버튼
   ↓
8. 결과 화면에서 상세 타임라인 확인 가능
   - 시간 구간별 FAKE/REAL 표시
   - 각 구간의 확률 표시
```

### 시나리오 3: 분석 결과 공유 및 리포트 생성

```
1. 분석 결과 화면에서 "리포트 생성" 버튼 클릭
   ↓
2. 리포트 화면에서 분석 결과 요약 확인
   ↓
3. 리포트 다운로드 또는 공유
   ↓
4. 커뮤니티 화면에서 다른 사용자들과 결과 공유 및 토론
```

---

## 1-1. 기능 구현 충실도 (12점)

### Must 기능 (3점) - 총 10개 항목, 모두 정상 동작

#### 백엔드 기능 (6개 항목)
1. ✅ **딥페이크 탐지 API** (`POST /analyze-video/`) - **완전 구현**
   - 비디오 파일 업로드 및 분석 요청 처리
   - JSON 형식 결과 반환
   - 정상 동작 확인

2. ✅ **딥러닝 모델 추론** - **완전 구현**
   - PyTorch 기반 MesoNet 모델 사용
   - 모델 로딩 및 추론 파이프라인 완성
   - 정상 동작 확인

3. ✅ **비디오 처리** - **완전 구현**
   - OpenCV를 활용한 프레임 추출
   - 이미지 전처리 및 리사이즈 (256x256)
   - 정상 동작 확인

4. ✅ **얼굴 감지** - **완전 구현**
   - OpenCV Haar Cascade 얼굴 감지
   - 얼굴 영역 crop 및 검증
   - 정상 동작 확인

5. ✅ **타임라인 생성** - **완전 구현**
   - 프레임별 분석 결과를 시간 구간별 세그먼트로 그룹화
   - `create_smart_timeline` 함수로 최소 2초 이상 구간 생성
   - 정상 동작 확인

6. ✅ **결과 API** (`GET /get-result/{video_id}`) - **완전 구현**
   - 분석 결과 조회 API
   - JSON 형식 반환
   - 정상 동작 확인

#### 프론트엔드 기능 (4개 항목)
7. ✅ **비디오 녹화** - **완전 구현**
   - 카메라를 통한 직접 녹화 (expo-camera)
   - 앨범에서 영상 선택 (expo-image-picker)
   - 정상 동작 확인

8. ✅ **비디오 업로드** - **완전 구현**
   - FormData를 활용한 백엔드 서버로 영상 전송
   - axios 및 fetch API 사용
   - 정상 동작 확인

9. ✅ **분석 결과 표시** - **완전 구현**
   - 타임라인 기반 분석 결과 시각화
   - 확률 및 FAKE/REAL 판정 표시
   - 정상 동작 확인

10. ✅ **Android 플로팅 위젯** - **완전 구현**
    - Android MediaProjection API 활용
    - Foreground Service로 백그라운드 실행
    - 스크린 레코딩 및 즉시 분석 기능
    - 정상 동작 확인

**Must 기능 점수: 3점 (10/10 항목 완전 구현)**

---

### Should 기능 (3점) - 총 4개 항목, 모두 정상 동작

1. ✅ **스마트 프레임 샘플링** - **완전 구현**
   - 영상 길이에 따라 동적 프레임 샘플 수 조정
   - 5초 미만: 3배 샘플링
   - 10초 미만: 2배 샘플링
   - 10초 이상: 1.5배 샘플링
   - 정상 동작 확인

2. ✅ **로딩 애니메이션** - **완전 구현**
   - SVG 기반 로딩 애니메이션 (loding1.svg ~ loding4.svg)
   - 0.25초 간격으로 순차 재생
   - 위젯 및 앱 내 분석 화면 모두 적용
   - 정상 동작 확인

3. ✅ **Firebase Storage 연동** - **완전 구현**
   - Firebase Admin SDK 활용
   - 영상 파일 안전 저장
   - Firebase Storage 업로드 기능 구현
   - 정상 동작 확인

4. ✅ **타임라인 시각화** - **완전 구현**
   - 프레임별 분석 결과를 시간 구간별로 색상 코딩
   - Timeline 컴포넌트로 시각화
   - FAKE/REAL 구간 구분 표시
   - 정상 동작 확인

**Should 기능 점수: 3점 (4/4 항목 완전 구현)**

---

### Could 기능 (3점) - 총 5개 항목, 4개 완전 구현, 1개 부분 구현

1. ✅ **플로팅 위젯 커스터마이징** - **완전 구현**
   - 위젯 버튼 아이콘 커스터마이징 (camera.svg, cap.svg, del.svg)
   - 배경 색상 커스터마이징 (GradientDrawable)
   - 녹화 상태에 따른 색상 변경
   - 정상 동작 확인

2. ✅ **분석 결과 아이콘 변경** - **완전 구현**
   - 분석 완료 시 위젯 아이콘이 we2.svg로 자동 변경
   - 닫기 버튼 클릭 시 원래 아이콘으로 복원
   - 정상 동작 확인

3. ⚠️ **커뮤니티 기능** - **부분 구현**
   - CommunityScreen, CommunityWriteScreen, CommunityDetailScreen 화면 구현됨
   - API 연동 코드는 있으나 실제 백엔드 엔드포인트 미구현
   - 기본 UI 구조만 완성, 실제 기능은 미완성
   - 부분 점수 부여 (0.5점)

4. ⚠️ **리포트 생성** - **부분 구현**
   - 백엔드에 report_generator.py로 PDF/Excel 리포트 생성 기능 구현됨
   - 프론트엔드 ReportScreen은 기본 화면만 구현 (기능 미연동)
   - 백엔드 기능은 완성되었으나 프론트엔드 연동 미완성
   - 부분 점수 부여 (0.5점)

5. ⚠️ **메트릭스 화면** - **부분 구현**
   - MetricsScreen 화면은 기본 구조만 구현 (기능 미구현)
   - 분석 통계 및 성능 지표 확인 기능 미구현
   - 부분 점수 부여 (0.3점)

**Could 기능 점수: 1.3점 (2/5 항목 완전 구현, 3/5 항목 부분 구현)**

---

### 총점 계산

- **Must 기능**: 3점 (10/10 항목 완전 구현)
- **Should 기능**: 3점 (4/4 항목 완전 구현)
- **Could 기능**: 1.3점 (2/5 항목 완전 구현, 3/5 항목 부분 구현)

**기능 구현 충실도 총점: 7.3점 / 9점**

**상세 평가:**
- **Must 기능 (3점)**: 모든 항목이 완전히 구현되어 정상 동작함. 핵심 기능들이 모두 작동하여 프로젝트의 기본 목적을 달성함.
- **Should 기능 (3점)**: 모든 항목이 완전히 구현되어 사용자 경험 향상에 기여함. 스마트 샘플링, 로딩 애니메이션, Firebase 연동, 타임라인 시각화가 모두 정상 동작함.
- **Could 기능 (1.3점)**: 플로팅 위젯 커스터마이징과 분석 결과 아이콘 변경은 완전히 구현되었으나, 커뮤니티 기능, 리포트 생성, 메트릭스 화면은 UI만 구현되고 실제 기능 연동은 미완성 상태임.

---

## 4. 기술 요구사항 & 제약 (6점, 각 3점)

### 1) 클라이언트/백엔드/AI/DB 등 기술 스택

#### 프론트엔드 (클라이언트)
- **React Native + Expo** (SDK 51): 크로스 플랫폼 모바일 앱 개발
- **TypeScript**: 타입 안정성 보장
- **React Navigation**: 화면 네비게이션 관리
- **expo-camera** (~15.0.16): 카메라 접근 및 비디오 녹화
- **expo-av** (~14.0.7): 비디오 재생 및 오디오 처리
- **expo-image-picker** (~15.1.0): 갤러리에서 영상 선택
- **expo-file-system** (~17.0.1): 파일 시스템 접근
- **react-native-svg** (^15.2.0): SVG 아이콘 렌더링
- **axios** (^1.6.0): HTTP 클라이언트
- **firebase** (^10.7.1): Firebase Storage 연동
- **Android Native (Kotlin)**: 플로팅 위젯 구현 (FloatingService.kt)

#### 백엔드
- **FastAPI** (0.104.1): RESTful API 서버
- **Uvicorn** (0.24.0): ASGI 서버
- **Python** (3.8+): 백엔드 개발 언어

#### AI/ML
- **PyTorch** (>=2.0.0): 딥러닝 프레임워크
- **MesoNet**: 딥페이크 탐지 모델 (PyTorch 구현, 256x256 입력, dropout=0.4)
- **OpenCV** (>=4.8.0): 비디오 처리 및 프레임 추출
- **MediaPipe** (>=0.10.0): 얼굴 감지
- **Transformers** (>=4.35.0): Hugging Face Transformers 라이브러리
- **scikit-learn** (>=1.3.0): 머신러닝 유틸리티

#### 데이터베이스/Storage
- **Firebase Storage**: 영상 파일 저장
- **Firebase Firestore**: 사용자 메타데이터 및 분석 결과 저장 (선택적)

#### 기타
- **reportlab** (>=4.0.0): PDF 리포트 생성
- **openpyxl** (>=3.1.0): Excel 파일 생성
- **pydantic** (>=2.4.0): 데이터 검증
- **aiofiles** (>=23.2.0): 비동기 파일 처리

### 2) 제약 및 리스크

#### 성능 제약
- **CPU 기반 추론**: 현재 모델 추론이 CPU에서 수행되어 처리 시간이 소요됨 (GPU 서버 배포 시 개선 가능)
- **프레임 샘플링**: 영상 전체를 분석하지 않고 샘플링된 프레임만 분석하여 정확도에 영향 가능
- **모바일 기기 성능**: 저사양 기기에서 영상 처리 시 성능 저하 가능

#### 보안 제약
- **모델 파일 보안**: 모델 가중치 파일(.pt)은 Git에 포함되지 않아 별도 관리 필요
- **Firebase 키 관리**: Firebase 서비스 계정 키 파일은 보안상 Git에 포함되지 않음
- **암호화 미구현**: 현재 데이터 암호화 기능 미구현 (향후 AES256 암호화 구현 예정)

#### 플랫폼 제약
- **Android 전용**: 현재 Android 플랫폼만 지원 (iOS 미지원)
- **Android 버전 요구사항**: Android 6.0 (API Level 23) 이상 필요
- **오버레이 권한**: 플로팅 위젯 사용을 위한 오버레이 권한 필요

#### API 비용
- **Firebase Storage**: 영상 파일 저장 시 스토리지 사용량에 따른 비용 발생
- **서버 호스팅**: 백엔드 서버 호스팅 비용 (현재 로컬 개발 환경)

#### 기술적 리스크
- **모델 정확도**: 딥페이크 기술의 발전에 따라 탐지 정확도 저하 가능
- **의존성 호환성**: Python 패키지 버전 호환성 문제 가능
- **메모리 사용량**: 대용량 영상 처리 시 메모리 부족 가능

---

## 5. 향후 계획 (4점, 각 2점)

### 1) 최소 달성 목표

#### 단기 목표 (1-3개월)
- **안정성 개선**
  - 오류 처리 강화 및 네트워크 오류 시 재시도 로직 구현
  - 메모리 누수 방지 및 성능 최적화
  - 모델 로딩 실패 시 명확한 에러 메시지 제공

- **사용자 경험 개선**
  - 분석 진행률 표시 기능 추가
  - 결과 화면 UI/UX 개선 (타임라인 시각화 강화)
  - 다크 모드 지원

- **문서화 완성**
  - 사용자 가이드 작성 (플로팅 위젯 사용법, 분석 결과 해석)
  - API 문서화 (Swagger/OpenAPI)
  - 개발자 가이드 작성 (설치, 빌드, 배포)

#### 중기 목표 (3-6개월)
- **iOS 지원**
  - React Native iOS 빌드 및 테스트
  - iOS 화면 녹화 기능 구현 (ReplayKit 활용)
  - iOS 권한 처리 및 App Store 배포 준비

- **성능 최적화**
  - GPU 서버 활용으로 분석 속도 향상 (현재 CPU 기반)
  - 모델 경량화를 통한 모바일 기기에서의 실시간 추론 가능성 검토
  - 프레임 샘플링 알고리즘 개선

- **보안 강화**
  - API 인증 시스템 구현 (JWT 토큰 기반)
  - 데이터 암호화 (AES256) 구현
  - Firebase 보안 규칙 강화

### 2) 발전 방향

#### 장기 목표 (6개월 이상)

1. **AI/ML 개선**
   - 더 정확한 딥페이크 탐지 모델 개발 (EfficientNet-B0 앙상블 활용)
   - 실시간 스트리밍 분석 지원
   - 다양한 딥페이크 기술 탐지 (FaceSwap, DeepFaceLab 등)
   - 자체 딥러닝 모델 학습 및 배포 파이프라인 구축

2. **플랫폼 확장**
   - **웹 버전**: 브라우저에서 사용 가능한 웹 애플리케이션 개발
   - **데스크톱 버전**: Windows, macOS, Linux 지원
   - **브라우저 확장 프로그램**: Chrome, Firefox 확장 프로그램 개발
   - **API 서비스**: 타사 서비스에 RESTful API 제공

3. **기능 확장**
   - **히스토리 관리**: 분석 기록 저장 및 조회 기능
   - **공유 기능**: 소셜 미디어 공유 및 리포트 생성
   - **신고 시스템**: 플랫폼별 딥페이크 신고 연동
   - **커뮤니티**: 사용자 간 정보 공유 및 토론 기능 (현재 기본 구조만 구현됨)
   - **알림 시스템**: 특정 확률 이상 탐지 시 알림 제공

4. **비즈니스 모델**
   - **Freemium 모델**: 기본 기능 무료, 고급 기능 유료
   - **B2B 라이선싱**: 미디어 기업, 플랫폼 서비스에 기술 제공
   - **API 서비스**: 개발자 대상 API 구독 서비스

5. **연구 및 개발**
   - **오픈소스화**: 일부 기능 오픈소스로 공개
   - **학술 논문 발표**: 딥페이크 탐지 연구 성과 공유
   - **연구 협력**: 대학 및 연구기관과 협력 연구

6. **사회적 기여**
   - **교육 프로그램**: 미디어 리터러시 교육 콘텐츠 제공
   - **팩트체크 파트너십**: 팩트체크 기관과 협력
   - **정책 제안**: 딥페이크 규제 정책 제안
   - **국제 협력**: 글로벌 딥페이크 대응 네트워크 참여

